{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "%rm -rf LLaMA-Factory\n",
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory\n",
    "%ls\n",
    "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
    "!pip uninstall -y jax\n",
    "!pip install -e .[torch,bitsandbytes,liger-kernel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y vllm\n",
    "!pip install llamafactory[metrics]==0.7.1\n",
    "!pip install accelerate==0.30.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看llamafactory是否安装成功\n",
    "!llamafactory-cli version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查torch和显卡\n",
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载模型\n",
    "!git clone https://www.modelscope.cn/baichuan-inc/Baichuan2-7B-Chat.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /home/syq/fine_tuning/test1/LLaMA-Factory/Baichuan2-7B-Chat/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型是否导入成功\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# 本地模型路径\n",
    "model_dir = \"/home/syq/fine_tuning/test1/LLaMA-Factory/Baichuan2-7B-Chat\"\n",
    "\n",
    "# 加载分词器\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir, device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.float16\n",
    "    )\n",
    "    print(\"Tokenizer loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading tokenizer:\", e)\n",
    "\n",
    "# 加载模型\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir, device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.float16\n",
    "    )\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading model:\", e)\n",
    "\n",
    "# 加载生成配置\n",
    "try:\n",
    "    model.generation_config = GenerationConfig.from_pretrained(model_dir)\n",
    "    print(\"Generation config loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading generation config:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 llamafactory-cli train \\\n",
    "    --stage sft \\\n",
    "    --do_train \\\n",
    "    --model_name_or_path /home/syq/fine_tuning/test1/LLaMA-Factory/Baichuan2-7B-Chat \\\n",
    "    --dataset train \\\n",
    "    --dataset_dir /home/syq/fine_tuning/test1/LLaMA-Factory/data \\\n",
    "    --template baichuan2 \\\n",
    "    --finetuning_type lora \\\n",
    "    --output_dir ./saves/baichuan/lora/sft \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --cutoff_len 1024 \\\n",
    "    --preprocessing_num_workers 16 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --logging_steps 100 \\\n",
    "    --warmup_steps 500 \\\n",
    "    --save_steps 1000 \\\n",
    "    --eval_steps 1000 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --load_best_model_at_end \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 3.0 \\\n",
    "    --max_samples 1000 \\\n",
    "    --val_size 0.1 \\\n",
    "    --plot_loss \\\n",
    "    --fp16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
